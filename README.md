# Project 

## Robotic Hand 

I have recently fabricated a ROS integrated mobile robot and performed point to point autonomous navigation on it in a zoo themed arena. We used semantic segmentation for detecting roads in the arena along with custom trained animal recognition algorithm for detecting destination. The bot localised using wheel odometery along with feedback from pose estimation on data from an  over head camera. The project was made for Hardwired, an annual robotics event at our college where our team stood first among 30 participating teams.


## Hardware Used:

Most of the part of the hand is made up of wood that have been cut by the help of our Carpentary workshop T.As. 

## Materials used:

I have used mainly 4 components.

- Microcontroller board (Raspberrypi zero 2W)
- Servo Motors 
- Camera 

### Raspberrypi zero 2W

![This is an image](https://i2.wp.com/tutorial.cytron.io/wp-content/uploads/2021/10/RPI-ZERO2-W_highlight.jpg?resize=1024%2C656&ssl=1)


Raspberrypi is a microcontroller board which acts just as a mini computer which acts as a reciever for the hardware.It also sends output to the hardware for its working.

#### The connections
 




### Servo Motors 

![This is an image](https://circuitdigest.com/sites/default/files/field/image/Servo-Motor.jpg)

I have used 5 Servo Motors for each finger which are connected to each finger using string 

### Camera

I have used laptop camera for the sake of simplicity but I can use raspberrypi camera or any other camera also.


## Prerequisites

- Computer Vision
- Basics of Raspberrypi 

## Team Members

- [Pranshu Kedia](https://github.com/pranshu79)
- [Tanishka Nama]()





